# RAG-chatbot-with-bedrock-knowledgebase
a ğ—¥ğ—”ğ—š ğ—–ğ—µğ—®ğ˜ğ—¯ğ—¼ğ˜ ğ—¹ğ—²ğ˜ƒğ—²ğ—¿ğ—®ğ—´ğ—¶ğ—»ğ—´ ğ—¯ğ—¼ğ˜ğ—µ ğ—”ğ—ºğ—®ğ˜‡ğ—¼ğ—» ğ—•ğ—²ğ—±ğ—¿ğ—¼ğ—°ğ—¸ ğ—¸ğ—»ğ—¼ğ˜„ğ—¹ğ—²ğ—±ğ—´ğ—² ğ—¯ğ—®ğ˜€ğ—²/ğ—¦ğŸ¯ ğ—¯ğ˜‚ğ—°ğ—¸ğ—²ğ˜ and user-uploaded documents to provide accurate, context-aware responses. It also ğ—½ğ—¿ğ—¼ğ˜ƒğ—¶ğ—±ğ—²ğ˜€ ğ˜ğ—µğ—² ğ˜€ğ—¼ğ˜‚ğ—¿ğ—°ğ—²ğ˜€ ğ—¼ğ—³ ğ˜ğ—µğ—² ğ—¿ğ—²ğ˜€ğ—½ğ—¼ğ—»ğ˜€ğ—² and ğ—ºğ—®ğ—¶ğ—»ğ˜ğ—®ğ—¶ğ—»ğ˜€ ğ—°ğ—µğ—®ğ˜ ğ—µğ—¶ğ˜€ğ˜ğ—¼ğ—¿ğ˜†. 

ğŸ” Key Features:
- ğ——ğ—¼ğ—°ğ˜‚ğ—ºğ—²ğ—»ğ˜ ğ—¨ğ—½ğ—¹ğ—¼ğ—®ğ—± ğ—–ğ—®ğ—½ğ—®ğ—¯ğ—¶ğ—¹ğ—¶ğ˜ğ˜†: Support for PDF and TXT files allows users to enrich the chatbot's knowledge base with personal or proprietary documents.
- ğ—˜ğ—³ğ—³ğ—¶ğ—°ğ—¶ğ—²ğ—»ğ˜ ğ—¥ğ—²ğ˜ğ—¿ğ—¶ğ—²ğ˜ƒğ—®ğ—¹ ğ— ğ—²ğ—°ğ—µğ—®ğ—»ğ—¶ğ˜€ğ—º: Utilizes FAISS for vector-based similarity searches.
-ğ—¦ğ—¼ğ˜‚ğ—¿ğ—°ğ—²ğ˜€ ğ—³ğ—¼ğ—¿ ğ—¥ğ—²ğ˜€ğ—½ğ—¼ğ—»ğ˜€ğ—²ğ˜€: Ensures transparency and reliability by providing references to the original sources from which information was retrieved. This feature allows users to verify and delve deeper into the provided answers.
- ğ—–ğ—µğ—®ğ˜ ğ—›ğ—¶ğ˜€ğ˜ğ—¼ğ—¿ğ˜† ğ— ğ—®ğ—»ğ—®ğ—´ğ—²ğ—ºğ—²ğ—»ğ˜: Maintains a well-organized chat history.
- ğ—–ğ—¹ğ—²ğ—®ğ—¿ ğ—–ğ—µğ—®ğ˜ ğ—™ğ˜‚ğ—»ğ—°ğ˜ğ—¶ğ—¼ğ—»ğ—®ğ—¹ğ—¶ğ˜ğ˜†: Users can easily reset their conversation history

ğŸ› ï¸ ğ——ğ—¶ğ—¿ğ—²ğ—°ğ˜ ğ—ğ—»ğ—¼ğ˜„ğ—¹ğ—²ğ—±ğ—´ğ—² ğ—•ğ—®ğ˜€ğ—² ğ—œğ—»ğ˜ğ—²ğ—´ğ—¿ğ—®ğ˜ğ—¶ğ—¼ğ—» ğ—˜ğ˜…ğ—½ğ—¹ğ—®ğ—¶ğ—»ğ—²ğ—±: 
One of the standout features of my RAG Chatbot is it's ability to dynamically retrieve and integrate information directly from Amazon Bedrock knowledge base. Here's how it works:

ğ—¤ğ˜‚ğ—²ğ—¿ğ˜† ğ—˜ğ—ºğ—¯ğ—²ğ—±ğ—±ğ—¶ğ—»ğ—´: When a user submits a question, the system first converts the query into a high-dimensional vector using Amazon Bedrock's fully managed bedrock-runtime Embedding API. Leveraging this fully managed API ensures seamless scalability and reliability without the need for manual infrastructure management.

ğ—©ğ—²ğ—°ğ˜ğ—¼ğ—¿-ğ—•ğ—®ğ˜€ğ—²ğ—± ğ—¥ğ—²ğ˜ğ—¿ğ—¶ğ—²ğ˜ƒğ—®ğ—¹: This vector is then used to perform a similarity search against the knowledge base stored in FAISS, identifying the most relevant documents or passages based on cosine similarity. This is achieved through the ğ—¯ğ—²ğ—±ğ—¿ğ—¼ğ—°ğ—¸_ğ—®ğ—´ğ—²ğ—»ğ˜_ğ—¿ğ˜‚ğ—»ğ˜ğ—¶ğ—ºğ—².ğ—¿ğ—²ğ˜ğ—¿ğ—¶ğ—²ğ˜ƒğ—² method, which takes the ğ—¸ğ—»ğ—¼ğ˜„ğ—¹ğ—²ğ—±ğ—´ğ—²ğ—•ğ—®ğ˜€ğ—²ğ—œğ—± and a ğ—¿ğ—²ğ˜ğ—¿ğ—¶ğ—²ğ˜ƒğ—®ğ—¹ğ—¤ğ˜‚ğ—²ğ—¿ğ˜† containing the user's question. By utilizing this method, the chatbot efficiently fetches pertinent information directly from the knowledge base, thereby enhancing performance and reducing latency.

ğ—–ğ—¼ğ—»ğ˜ğ—²ğ˜…ğ˜ğ˜‚ğ—®ğ—¹ ğ—¥ğ—²ğ˜€ğ—½ğ—¼ğ—»ğ˜€ğ—² ğ—šğ—²ğ—»ğ—²ğ—¿ğ—®ğ˜ğ—¶ğ—¼ğ—»: The retrieved information serves as contextual input for the large language model (LLM), specifically Amazon Bedrock's fully managed Titan-TG1 Large LLM services, which generate a coherent and accurate response tailored to the user's query. 

If you're interested in seeing this in action or exploring collaboration opportunities, feel free to reach out or try it out yourself!
ğŸ”— Live App: https://lnkd.in/gVEJzM9c
